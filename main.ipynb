{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time\n", "from schedule_env import ScheduleEnv\n", "import torch\n", "from preprocessor import PreProcessor\n", "from Module.dqn import DQN\n", "from Module.drqn import DRQN\n", "from Module.dueling_drqn import DuelingDRQN\n", "import torch.optim as optim\n", "from itertools import count\n", "import config\n", "import matplotlib.pyplot as plt\n", "from schedule_kpi import schedule_kpi\n", "from schedule_inference import load_model\n", "from model_logger import clear_result, gantt_result\n", "from schedule_agent import ScheduleAgent\n", "import warnings\n", "warnings.filterwarnings(\"ignore\")  # ignore for server 2\n", "# Cuda detect\n", "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n", "print('GPU State:', device)\n", "s_time = time.time()\n", "print('Start preprocess ...')\n", "preprocessor = PreProcessor()\n", "preprocessor.process()\n", "print('preprocess End  {} seconds'.format(str(time.time() - s_time)))\n", "schedule_env = ScheduleEnv(preprocessor.jobs_info, preprocessor.equipments_list, preprocessor.job_actions,\n", "                           preprocessor.max_step, preprocessor.avg_op_order, preprocessor.action_map)\n", "test_env = ScheduleEnv(preprocessor.jobs_info, preprocessor.equipments_list, preprocessor.job_actions,\n", "                       preprocessor.max_step, preprocessor.avg_op_order, preprocessor.action_map)\n", "schedule_env.reset()\n", "attribute_count = list(preprocessor.jobs_info.observation.values())[0].get_one_observation().size"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if config.LOAD_MODEL:\n", "    policy_net = load_model(preprocessor, attribute_count, len(schedule_env.actions), device)\n", "else:\n", "    policy_net = DuelingDRQN(len(preprocessor.job_info_dict), attribute_count, len(preprocessor.action_map), device).to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = optim.RMSprop(policy_net.parameters(), lr=config.LEARNING_RATE)\n", "schedule_agent = ScheduleAgent(policy_net, device, len(preprocessor.job_info_dict), attribute_count,\n", "                               len(schedule_env.actions), optimizer, test_env, preprocessor.job_actions,\n", "                               preprocessor.action_map)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["returns = []\n", "best_return = config.BEST_RETURN\n", "best_observation = {}\n", "tolerance_step = config.TOLERANCE_STEP\n", "tolerance_count = 0\n", "total_step = 0\n", "for i_episode in range(config.TRAINING_EPISODE):\n", "    # Initialize the environment and state\n", "    state = schedule_env.reset()\n", "    for t in count():\n", "        # Select and perform an action\n", "        action = schedule_agent.select_action(state, schedule_env.job_info)\n", "        total_step += 1\n", "        _, reward, done = schedule_env.step(action.item())\n", "        reward = torch.tensor([reward], device=device)\n", "        next_state = schedule_env.get_current_state()\n", "        schedule_agent.memory.push(state, action, next_state, reward)\n", "        # Move to the next state\n", "        state = next_state\n\n", "        # Perform one step of the optimization (on the policy network)\n", "        loss = schedule_agent.optimize_model()\n", "        if total_step % config.LOG_INTERVAL == 0:\n", "            loss = loss.item() if loss else 'nan'\n", "            print(\"step {0} --> loss : {1} \".format(str(total_step), str(loss)))\n", "        if total_step % config.EVAL_INTERVAL == 0:\n", "            avg_return, observation = schedule_agent.test_agent(len(preprocessor.job_info_dict),\n", "                                                                preprocessor.equipments_list, False, num_episodes=2)\n", "            schedule_kpi(observation, preprocessor.equipments_list)\n", "            if best_return < avg_return:\n", "                best_return = avg_return\n", "                tolerance_count = 0\n", "                # Store good results\n", "                schedule_agent.save_best_observation(preprocessor.equipments_list, preprocessor.job_info_dict)\n", "                schedule_kpi(schedule_agent.best_observation, preprocessor.equipments_list)\n", "                # Save model\n", "                torch.save({'model_state_dict': schedule_agent.policy_net.state_dict(),\n", "                            'class_name': schedule_agent.policy_net.__class__.__name__\n", "                            }, config.MODEL_FILE, _use_new_zipfile_serialization=False)\n", "            else:\n", "                tolerance_count += 1\n", "                if tolerance_count == tolerance_step:\n", "                    break\n", "            returns.append(avg_return)\n", "            print(\"step {0} --> avg_return : {1}, best_return --> {2}\".format(str(total_step), str(avg_return),\n", "                                                                              str(best_return)))\n", "        if total_step % 5000 == 0:\n", "            # test_agent(agent.policy, test_env)\n", "            schedule_agent.test_agent(len(preprocessor.job_info_dict), preprocessor.equipments_list,\n", "                                      display_status=False, num_episodes=3)\n\n", "            # Plot\n", "            plt.plot(returns)\n", "            plt.savefig('return.png')\n", "            plt.close()\n", "        if done:\n", "            break\n\n", "    # Update the target network, copying all weights and biases in DQN\n", "    if i_episode % config.TARGET_UPDATE_PERIOD == 0:\n", "        schedule_agent.update_target_net()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Complete')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["finish_schedule_result = schedule_agent.best_observation_array[-1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print KPI score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\n\\nFinish Schedule Result:\")\n", "clear_result(finish_schedule_result, len(preprocessor.job_info_dict), len(preprocessor.equipments_list))\n", "schedule_kpi(schedule_agent.best_observation, preprocessor.equipments_list)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}